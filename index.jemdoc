# jemdoc


= Junchi Yang 

~~~
{}{img_left}{self.jpeg}{alt text}{130}{168}

I am a postdoctoral researcher at Argonne National Laboratory. I completed my Ph.D. in Computer Science at ETH Zurich, under the supervision of [https://odi.inf.ethz.ch/niaohe Niao He]. My research interest lies in optimization and its applications in machine learning. Prior to this, I received a master's degree in Industrial Engineering from the University of Illinois Urbana-Champaign. I received a bachelor's degree in Applied Mathematics and Economics from UCLA. 

Email: junchi.yang (at) anl (dot) gov

[https://www.linkedin.com/in/junchi-yang-455206b0/ Linkedin]. [https://scholar.google.com/citations?user=Av7wBOQAAAAJ&hl=en/ Google Scholar].
~~~

	

== News\

- \[2024.1\] Our paper "Parameter-Agnostic Optimization under Relaxed Smoothness" is accepted to AISATS 2024. 

- \[2024.1\] I started as a postdoctoral researcher at Argonne National Laboratory.

- \[2023.09\] Two co-first-authored papers are accepted to NeurIPS 2023. One of them is selected to be a spotlight paper. 

- \[2023.09\] I've successfully defended my PhD thesis titled "Towards Near-Optimal and Adaptive Algorithms in Minimax Optimization". Grateful for this academic journey.

- \[2023.06\] I am giving a talk at the 20th EUROpt Workshop in Budapest in August.

 - \[2023.05\] Our paper "[https://arxiv.org/pdf/2305.12475.pdf Two Sides of One Coin: the Limits of Untuned SGD and the Power of Adaptive Methods ]" is online. 

- \[2023.03\] I am giving a talk at the SIAM Conference on Optimization (OP23) in Seattle in June.

- \[2023.01\] Our paper "TiAda: A Time-scale Adaptive Algorithm For Nonconvex Minimax Optimization" is accepted by ICLR 2023.

- \[2022.09\] One paper is accepted by NeurIPS 2022 and one is accepted by NeurIPS OPT workshop.
 


	
== Publications 

(* indicates equal contribution) 

\n

- Parameter-Agnostic Optimization under Relaxed Smoothness\n
  Florian HÃ¼bler, *Junchi Yang*, Xiang Li, Niao He.\n
  AISTATS 2024 (preliminary version in NeurIPS OPT Workshop 2023) [https://arxiv.org/pdf/2311.03252.pdf \[arXiv\] ] 

- Optimal Guarantees for Algorithmic Reproducibility and Gradient Complexity in Convex Optimization\n
  Liang Zhang\*, *Junchi Yang*\*, Amin Karbasi, Niao He.\n
  NeurIPS 2023 (*spotlight*). [https://arxiv.org/pdf/2310.17759.pdf \[arXiv\] ] 

- Two Sides of One Coin: the Limits of Untuned SGD and the Power of Adaptive Methods\n
  *Junchi Yang*\*, Xiang Li\*, Ilyas Fatkhullin, and Niao He.\n
  NeurIPS 2023. [https://arxiv.org/pdf/2305.12475.pdf \[arXiv\] ] 


- TiAda: A Time-Scale Adaptive Algorithm For Nonconvex Minimax Optimization\n
  Xiang Li, *Junchi Yang*, and Niao He.\n
  ICLR 2023 (preliminary version in NeurIPS OPT Workshop 2022) [https://arxiv.org/pdf/2210.17478.pdf \[arXiv\] ]   [https://openreview.net/pdf?id=zClyiZ5V6sL \[ICLR\] ]


- Nest Your Adaptive Algorithm for Parameter-Agnostic Nonconvex Minimax Optimization\n
  *Junchi Yang*\*, \ Xiang Li\*, and Niao He.\n
  NeurIPS 2022 [https://arxiv.org/abs/2206.00743 \[arXiv\] ]  [https://proceedings.neurips.cc/paper_files/paper/2022/hash/488b8db9ec118c3d750c34d1812a5a3a-Abstract-Conference.html \[NeurIPS\] ]

- Faster Single-Loop Algorithms for Minimax Optimization without Strong Concavity\n
  *Junchi Yang*, Antonio Orvieto, Aurelien Lucchi, and Niao He.\n
  AISTATS 2022 [https://arxiv.org/abs/2112.05604 \[arXiv\] ] [https://proceedings.mlr.press/v151/yang22b.html \[AISTATS\] ]


- The Complexity of Nonconvex-Strongly-Concave Minimax Optimization\n
  Siqi Zhang\*, \ *Junchi Yang*\*, Cristobal Guzman, Negar Kiyavash and Niao He.\n
  UAI 2021 [https://arxiv.org/abs/2103.15888 \[arXiv\] ] [https://www.auai.org/uai2021/pdf/uai2021.205.pdf \[UAI\] ]

- A Catalyst Framework for Minimax Optimization\n
  *Junchi Yang*, Siqi Zhang, Negar Kiyavash, and Niao He.\n
  NeurIPS 2020 [https://proceedings.neurips.cc/paper/2020/hash/3db54f5573cd617a0112d35dd1e6b1ef-Abstract.html \[NeurIPS\] ]

- Global Convergence and Variance Reduction for a Class of Nonconvex-Nonconcave Minimax Problems\n
  *Junchi Yang*, Negar Kiyavash, and Niao He.\n
  NeurIPS 2020 [https://arxiv.org/abs/2002.09621 \[arXiv\] ] [https://proceedings.neurips.cc/paper/2020/hash/0cc6928e741d75e7a92396317522069e-Abstract.html \[NeurIPS\] ]






== Talks\

- 20th EUROpt Workshop 2023. Title: "From SGD to Adaptive Methods: Benefits of Adaptive Gradient Techniques".

- SIAM Conference on Optimization 2023 (OP23). Title: "Adaptive Algorithms for Nonconvex Minimax Optimization".

- CSL Student Conference 2021. Title: "A Catalyst Framework for Minimax Optimization".

- INFORMS 2020 Annual Meeting. Title: "Simple and Efficient Algorithms for Classes of Nonconvex Minimax Optimization".




== Teaching
\
- Optimization for Data Science. ETH Zurich. 2022 Spring, 2023 Winter.

- Foundations of Reinforcement Learning. ETH Zurich. 2021 Fall.

- Analysis of Data. UIUC. 2019 Fall. 

== Service

Reviewer for NeurIPS, ICML, ICLR, AISTATS and TMLR.

== Miscellaneous

- I received ISE Student Fellowship at UIUC 2017-2018. 

- Top reviewer for NeurIPS 2022.

- I play [https://raw.githubusercontent.com/Junchi-Michael-Yang/Junchi-Michael-Yang.github.io/main/volleyball2.jpg volleyball] and used to play badminton and table tennis. I am learning [https://raw.githubusercontent.com/Junchi-Michael-Yang/Junchi-Michael-Yang.github.io/main/snowboarding.JPG snowboarding] and tennis.





